{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b61fced",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tools\n",
    "from langchain_community.tools import ArxivQueryRun, WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper, ArxivAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e708ceaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv\n"
     ]
    }
   ],
   "source": [
    "api_wrapper_arxiv=ArxivAPIWrapper(top_k_results=2,doc_content_chars_max=500)\n",
    "arxiv=ArxivQueryRun(api_wrapper=api_wrapper_arxiv,description=\"Query arxiv papers\")\n",
    "print(arxiv.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22f55cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Published: 2024-07-22\\nTitle: Attention Is All You Need But You Don't Need All Of It For Inference of Large Language Models\\nAuthors: Georgy Tyukin, Gbetondji J-S Dovonon, Jean Kaddour, Pasquale Minervini\\nSummary: The inference demand for LLMs has skyrocketed in recent months, and serving\\nmodels with low latencies remains challenging due to the quadratic input length\\ncomplexity of the attention layers. In this work, we investigate the effect of\\ndropping MLP and attention layers at inference time o\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv.invoke(\"Attention is all you need.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8f6d0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikipedia\n"
     ]
    }
   ],
   "source": [
    "api_wrapper_wiki=WikipediaAPIWrapper(top_k_results=2,doc_content_chars_max=500)\n",
    "wikipedia=WikipediaQueryRun(api_wrapper=api_wrapper_wiki,description=\"Query wiki information\")\n",
    "print(wikipedia.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49f1a2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Page: Career of Virat Kohli\\nSummary: Virat Kohli's senior career began when he made his debut in List A cricket, playing against Services in the Ranji One-Day Trophy, but he did not have the opportunity to bat during the match. On the international stage, he has been representing India since he was included in the ODl squad for the tour of Sri Lanka. Kohli was part of the team during India won the 2011 Cricket World Cup, the 2013 ICC Champions Trophy, the 2024 ICC T20 World Cup and 2025 ICC Cham\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia.invoke(\"What's the date of birth of Virat Kohli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36890fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"]=os.getenv(\"TAVILY_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65df3d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tavily - It's a tool to connect LLM to internet\n",
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "tavily = TavilySearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4e5a541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Tell me the recent news about Formula 1',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'url': 'https://www.newsnow.com/us/Sports/F1',\n",
       "   'title': 'F1 News | Latest Formula One News - NewsNow',\n",
       "   'content': 'Latest F1 news in a live feed, including breaking news, race results, driver interviews, analysis, commentary and all updates relating to Formula 1 racing.',\n",
       "   'score': 0.74273956,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.motorsport.com/f1/news/',\n",
       "   'title': 'The Latest Formula 1 News, Articles & F1 Results - Motorsport.com',\n",
       "   'content': 'Updated F1 news and LIVE text coverage on all GP races. From practice and qualifying to the main race event. Photos, videos, results, driver stats and more.',\n",
       "   'score': 0.6780931,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.formula1.com/en/latest',\n",
       "   'title': 'Latest F1 News',\n",
       "   'content': \"Don't miss a Formula 1 moment – with the latest news, videos, standings and results. Go behind the scenes and get analysis straight from the paddock.\",\n",
       "   'score': 0.64344186,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.autosport.com/f1/',\n",
       "   'title': 'Latest Formula 1 News, Analysis, Results and More - Autosport',\n",
       "   'content': 'Max Verstappen admits he needs help from Lando Norris and Oscar Piastri to overhaul an average of nine points per race weekend in the 2025 Formula 1 title',\n",
       "   'score': 0.60610276,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.bbc.com/sport/formula1',\n",
       "   'title': 'F1 - Latest News, Results & Schedule - BBC Sport',\n",
       "   'content': \"More F1 news and analysis · Driver Villars starts legal action against FIA · How Jacques became the voice of F1 · Aston Martin avoid penalty for 'very minor'\",\n",
       "   'score': 0.5832277,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 0.9,\n",
       " 'request_id': '8880d6ae-c534-4b01-96de-e5841cf12c62'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily.invoke(\"Tell me the recent news about Formula 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c686ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [arxiv, wikipedia, tavily]\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "ll=ChatGroq(model=\"llama-3.1-8b-instant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ddb4165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I don't have information on the 2025 IPL winner. My knowledge cutoff is December 2023, and the 2025 IPL season has not yet occurred. I can provide information on past IPL winners, though.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 43, 'total_tokens': 89, 'completion_time': 0.070452668, 'prompt_time': 0.003280207, 'queue_time': 0.034822795, 'total_time': 0.073732875}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_020e283281', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--22284890-24cb-417b-a8ec-135d28bb93a2-0', usage_metadata={'input_tokens': 43, 'output_tokens': 46, 'total_tokens': 89})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll.invoke(\"Tell me the 2025 IPL winner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87fe8621",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools=ll.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82050fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '2a239x2ga', 'function': {'arguments': '{\"include_favicon\":true,\"include_images\":true,\"query\":\"ChatGPT Atlas latest news\",\"search_depth\":\"advanced\",\"start_date\":\"2024-01-01\",\"topic\":\"news\"}', 'name': 'tavily_search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 1905, 'total_tokens': 1964, 'completion_time': 0.085761387, 'prompt_time': 0.121531379, 'queue_time': 0.075672186, 'total_time': 0.207292766}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_9ca2574dca', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--88c120a6-fe44-4cb7-9d71-d20170aa8103-0', tool_calls=[{'name': 'tavily_search', 'args': {'include_favicon': True, 'include_images': True, 'query': 'ChatGPT Atlas latest news', 'search_depth': 'advanced', 'start_date': '2024-01-01', 'topic': 'news'}, 'id': '2a239x2ga', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1905, 'output_tokens': 59, 'total_tokens': 1964})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm_with_tools.invoke(\"What is the latest news about ChatGPT Atlas\")\n",
    "\n",
    "# Display structured output\n",
    "print(\"=\" * 80)\n",
    "print(\"RESPONSE CONTENT:\")\n",
    "print(\"=\" * 80)\n",
    "print(response.content)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Check if there are tool calls\n",
    "if hasattr(response, 'tool_calls') and response.tool_calls:\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"TOOL CALLS ({len(response.tool_calls)}):\")\n",
    "    print(\"=\" * 80)\n",
    "    for i, tool_call in enumerate(response.tool_calls, 1):\n",
    "        print(f\"\\n[{i}] Tool: {tool_call.get('name', 'N/A')}\")\n",
    "        print(f\"    ID: {tool_call.get('id', 'N/A')}\")\n",
    "        print(f\"    Arguments: {tool_call.get('args', {})}\")\n",
    "else:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"TOOL CALLS: None\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c3509f",
   "metadata": {},
   "source": [
    "### Alternative: Using JSON for even more structured output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9e6fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "response = llm_with_tools.invoke(\"What is the latest news about ChatGPT Atlas\")\n",
    "\n",
    "# Create structured output dictionary\n",
    "output = {\n",
    "    \"content\": response.content,\n",
    "    \"tool_calls\": [],\n",
    "    \"response_metadata\": response.response_metadata if hasattr(response, 'response_metadata') else None\n",
    "}\n",
    "\n",
    "# Add tool calls if present\n",
    "if hasattr(response, 'tool_calls') and response.tool_calls:\n",
    "    for tool_call in response.tool_calls:\n",
    "        output[\"tool_calls\"].append({\n",
    "            \"name\": tool_call.get('name'),\n",
    "            \"id\": tool_call.get('id'),\n",
    "            \"args\": tool_call.get('args', {})\n",
    "        })\n",
    "\n",
    "# Pretty print JSON\n",
    "print(json.dumps(output, indent=2, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd89e37e",
   "metadata": {},
   "source": [
    "### Helper function for structured output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74249c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_structured_response(response, show_metadata=False):\n",
    "    \"\"\"\n",
    "    Print LLM response in a structured, readable format.\n",
    "    \"\"\"\n",
    "    print(\"╔\" + \"=\" * 78 + \"╗\")\n",
    "    print(\"║\" + \" \" * 20 + \"LLM RESPONSE\" + \" \" * 46 + \"║\")\n",
    "    print(\"╠\" + \"=\" * 78 + \"╣\")\n",
    "    print(\"║ CONTENT:\" + \" \" * 69 + \"║\")\n",
    "    print(\"╠\" + \"─\" * 78 + \"╣\")\n",
    "    \n",
    "    # Print content with proper indentation\n",
    "    content_lines = str(response.content).split('\\n')\n",
    "    for line in content_lines:\n",
    "        # Truncate very long lines\n",
    "        if len(line) > 76:\n",
    "            line = line[:73] + \"...\"\n",
    "        print(f\"║ {line:<77}║\")\n",
    "    \n",
    "    print(\"╠\" + \"=\" * 78 + \"╣\")\n",
    "    \n",
    "    # Tool calls section\n",
    "    if hasattr(response, 'tool_calls') and response.tool_calls:\n",
    "        print(f\"║ TOOL CALLS: {len(response.tool_calls)}\" + \" \" * (67 - len(str(len(response.tool_calls)))) + \"║\")\n",
    "        print(\"╠\" + \"─\" * 78 + \"╣\")\n",
    "        for i, tool_call in enumerate(response.tool_calls, 1):\n",
    "            tool_name = tool_call.get('name', 'N/A')\n",
    "            print(f\"║ [{i}] {tool_name}\" + \" \" * (73 - len(tool_name) - len(str(i))) + \"║\")\n",
    "            if tool_call.get('args'):\n",
    "                args_str = str(tool_call['args'])\n",
    "                if len(args_str) > 74:\n",
    "                    args_str = args_str[:71] + \"...\"\n",
    "                print(f\"║     Args: {args_str:<68}║\")\n",
    "    else:\n",
    "        print(\"║ TOOL CALLS: None\" + \" \" * 62 + \"║\")\n",
    "    \n",
    "    # Metadata section (optional)\n",
    "    if show_metadata and hasattr(response, 'response_metadata'):\n",
    "        print(\"╠\" + \"=\" * 78 + \"╣\")\n",
    "        print(\"║ METADATA:\" + \" \" * 68 + \"║\")\n",
    "        print(\"╠\" + \"─\" * 78 + \"╣\")\n",
    "        metadata_str = str(response.response_metadata)\n",
    "        if len(metadata_str) > 76:\n",
    "            metadata_str = metadata_str[:73] + \"...\"\n",
    "        print(f\"║ {metadata_str:<77}║\")\n",
    "    \n",
    "    print(\"╚\" + \"=\" * 78 + \"╝\")\n",
    "\n",
    "# Example usage\n",
    "response = llm_with_tools.invoke(\"What is the latest news about ChatGPT Atlas\")\n",
    "print_structured_response(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202b5c63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
